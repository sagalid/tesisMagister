\subsection{Metaheuristics}

\subsubsection{Definition}
~\\
~\\
The $meta$ and $heuristic$ are Greek words, $meta$ it means $higher level$ and $heuristics$ means $to$ $find$, $to$ $know$ or $to$ $discover$. Metaheuristics are a set of intelligent strategies to enhance the efficiency of heuristic procedures.\\
A metaheuristic will be successful on a given optimizaction problem if it can provide a balance between exploration and exploitation. Exploration means to generate diverse solutions so as to explore the search space on the global scale, while exploitation means search in a local region by exploiting the information that a current good solution is found in this region.
exploration, often by use of randomization, which enables an algorithm to have the ability to jump out of any local optimum so as to explore the search globally.

\subsubsection{Clasification}
~\\
~\\
The different metaheuristic approaches can be characterized by different aspects concerning the search path they follow or how memory is exploited \cite{citeulike:1859945}. A majority of these algorithms has a stochastic behavior and mimics biological or  physical processes. The classification presented was proposed by Beheshti et al. \cite{Beheshti:2014:CCA:2563733.2564085}, and can be understood better as shown in the (Figure \ref{fig:classification-of-mh}).

\squeezeup
\begin{figure}[ht]
	\centering
  \includegraphics[width=0.70\textwidth]{MarcoTeorico/imagenes/classification_mh.png}
	\caption{Classification of metaheuristic}\label{fig:classification-of-mh}
\end{figure}
\squeezeup


\paragraph{Nature-inspired vs. non-nature inspiration }
This class is based on the origin of algorithm. The majority of meta-heuristics are nature-inspired algorithms such as Black Hole (BH) \cite{Rubio2016}, Particle Swarm Optimization (PSO) \cite{Duran:2010:CPS:1645454.1645859} and Genetic Algorithms (GA) \cite{DBLP:conf/icsi/CrawfordSPJPO14}. Also, some of them are non-nature-inspired algorithms like Iterated Local Search (ILS) \cite{DBLP:journals/networks/AringhieriGHS16} and TabuSearch (TS) \cite{DBLP:journals/eswa/SotoCGMP13}.

\paragraph{Population-based vs. single-point search}
There is a certain group of metaheuristics, which can be classified by the number of solutions in the lifecycle or execution, such as Trajectory methods, which are the algorithms working based on a single solution at any time (Figure \ref{fig:trajectory-method}). On the other hand Population-based algorithms perform search with multiple initial points in a parallel style. Examples of these metaheuristics can be: Harmony Search (HS) \cite{DBLP:conf/ccece/Al-AjmiE14}, GA \cite{Aupetit2008} and PSO. 

\squeezeup
\begin{figure}[H]
	\centering
  \includegraphics[width=0.55\textwidth]{MarcoTeorico/imagenes/trajectory-mh.png}
	\caption{Trajectory-based method}\label{fig:trajectory-method}
\end{figure}
\squeezeup

\paragraph{Dynamic vs. static objective function}
Another way of classifying metaheuristics, is by the way of utilizing the objective function, some algorithms maintain the objective function intact throughout the execution cycle, while others modify the objective function according to information collected at runtime.\\
An example of the second case presented, is Guided Local Search (GLS) \cite{DBLP:journals/eor/VansteenwegenSBO09}.  The idea behind this approach is to escape from local optima by changing the search landscape. 

\paragraph{One vs. various neighborhood structures}
The majority of metaheuristic algorithms apply one single neighborhood structure. The fitness landscape topology does not alter in the course of the algorithm while others, like Variable Neighborhood Search (VNS) \cite{DBLP:journals/anor/SarasolaDSA16}, employ a set of neighborhood structures. This latter structure gives the possibility to diversify the search by swapping between different fitness landscapes.

\paragraph{Memory usage vs. memoryless methods}
One of the most interesting variables to classify a metaheuristic is undoubtedly use of memory. Short term usually is different from long term memory. The first kind usually keeps track of recently performed moves, or decisions taken. The second is usually an accumulation of synthetic parameters about the search. 

\subsubsection{Related terms}
\paragraph{Operator} 
Unitary procedure for transforming information or implement the behavior of the algrithm.

\paragraph{Solution} 
Array of $n$ columns containing a solution for a given problem. In the binary case, the posible values are $0$ and $1$.

\paragraph{Constrain} 
Conditions to be met to find a viable solution.

\paragraph{Benchmark} 
Optimal set of known problem instances to validate the propose algorithm.

\paragraph{Objective Function}  
Implements the mathematical expression representing the problem to solve. The guiding objective function is related to the goal to achieve.

\paragraph{Fitness} 
Value resulting by applying the objective function to solution.

\paragraph{Matrix of Costs} 
Consist of $n$ columns vector containing the cost associated with each problem variable.

\paragraph{Optimal Value} 
Solution with the best fitness.

\paragraph{Domain} 
Set of possible values for the variable.

\paragraph{Matrix A} 
Matrix containing the restrictions for the given problem.

\paragraph{RPD} 
Relative Percentage Deviation.

\paragraph{Harmony Memory} 
Memory space which includes the population of the solution vectors.

\paragraph{Harmony Memory Size} 
Defines the amount of harmonies that can be stored in HM.

\paragraph{Harmony Memory Consideration Rate (HMCR)} 
In memory consideration, the value of decision variable ${x\textprime}_1$ is randomly selected from the historical values, other decision variables, $({x\textprime}_2, {x\textprime}_3,\dots,{x\textprime}_N)$ are sequentially selected in the same manner with probability where HMCR $\in$ (0,1).

\paragraph{Pitch Adjusting Rate (PAR)} 
Each decision variable ${x\textprime}_i$ assigned a value by memory considerations is pitch adjusted with the probability of PAR where PAR $\in$ (0,1).

\subsubsection{Framework for development}
In an effort to maintain consistency in the structure of the proposed metaheuristic development, a well-defined model is followed, in order to structure the development steps of the proposed technique (Figure \ref{fig:GuideSolvingSCP}).



